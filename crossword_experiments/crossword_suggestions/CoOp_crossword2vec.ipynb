{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CoOp_crossword2vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charu13a/knowledge-games/blob/word2vec/CoOp_crossword2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3hsoN3tQGJO",
        "colab_type": "text"
      },
      "source": [
        "This notebook contains an example of using word2vec to generate similar words for the crossword. The input is the words, along with the clues, which are used to supplement the context.\n",
        "Skip to final results [here](https://colab.research.google.com/drive/1Ocb3I-ZmlR3sneE90Bf0cJXMgHKbiJ_A#scrollTo=hHEzyraeT1EX). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p4Pp-0VQXop",
        "colab_type": "text"
      },
      "source": [
        "# Crossword words using word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MRP5Ou3UOyG",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPMgL7_YQAGx",
        "colab_type": "text"
      },
      "source": [
        "Download the pre-trained word vectors; this takes a minute (~1.5gb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxtlJuPsP-1S",
        "colab_type": "code",
        "outputId": "be679dad-ee62-4cfb-9e5f-4022addf7b6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-04 06:23:06--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.24.118\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.24.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘/root/input/GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  73.5MB/s    in 25s     \n",
            "\n",
            "2019-10-04 06:23:36 (63.0 MB/s) - ‘/root/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8esoW-EQgdm",
        "colab_type": "text"
      },
      "source": [
        "Install gensim, a useful NLP library that we will use to load word2vec embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I80py-ibQnd9",
        "colab_type": "code",
        "outputId": "af6e656f-5d49-479b-d545-5d4c590a739b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!pip install gensim\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.4)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.5)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.236)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.236 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.236)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.236->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.236->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCV9mB2-QtU-",
        "colab_type": "code",
        "outputId": "9a0f3327-436b-445a-e152-7a623a805209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz' # from above\n",
        "model = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCSVOdljRy07",
        "colab_type": "text"
      },
      "source": [
        "Add logging support."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upOc-8jUR07k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "from pprint import pprint # pretty print output\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5XP5DMRR-1K",
        "colab_type": "text"
      },
      "source": [
        "## Problem\n",
        "The goal is to find interesting related words given a set of words **and clues**, i.e. understand the ‘theme’ and get an effective ranking of the words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa3CGLTXTNsy",
        "colab_type": "text"
      },
      "source": [
        "Before we start, let us define an auxillary method which will remove words from the list which are not present in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCTYtv40TgNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# filters words not in the model vocabulary\n",
        "def filter_words_not_in_vocab(model, list_of_words):\n",
        "    word_vectors = model.wv\n",
        "    return list(filter(lambda x: x in word_vectors.vocab, list_of_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0JhC1ykJ7cS",
        "colab_type": "text"
      },
      "source": [
        "Additionally, we will need to remove words which have the same root as the input word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9tvrcF-KTsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "def filter_words_with_same_root(input_words):\n",
        "  def should_filter(word):\n",
        "    for x in input_words:\n",
        "      if(stemmer.stem(x) == stemmer.stem(word) or x in word or word in x):\n",
        "        return False\n",
        "    return True\n",
        "  return should_filter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZubWoW5SM1d",
        "colab_type": "text"
      },
      "source": [
        "### Metric for ranking: Frequency count\n",
        "This method finds the words which occur most number of times within top-N cosine distance of each input word.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV4CToV2SprV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import chain\n",
        "from collections import Counter\n",
        "\n",
        "# this method takes in a list of words and returns top 20 words which are \n",
        "# closest to most of the input words. \n",
        "def find_highest_frequency(model, list_of_words, nwords=20):\n",
        "    closest_words = []\n",
        "    map_words = []\n",
        "    for word in list_of_words:\n",
        "        words = model.similar_by_word(word, topn=50, restrict_vocab=None)\n",
        "        words = [x[0] for x in words]\n",
        "        for y in words:\n",
        "          map_words.append([word, y])\n",
        "        closest_words = closest_words + words\n",
        "    freq_count = Counter(chain(closest_words)).most_common(nwords)\n",
        "    return [x[0] for x in freq_count]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTiPvq0BSeDh",
        "colab_type": "text"
      },
      "source": [
        "## Gandhi 150"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y-3UEfxLLN-",
        "colab_type": "text"
      },
      "source": [
        "### Results without clues feeded to word2vec."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heSAn3sNTxW_",
        "colab_type": "text"
      },
      "source": [
        "1. Define the input words list. Input words are taken from a crossword."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8fPC9n7UJg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_list = ['Porbandar', 'Putli_Bai', 'Ram', 'Time', 'India', 'Aga', 'Abdul'\n",
        "              , 'soul', 'Charkha', 'butter', 'lawyer', 'Naidu', 'railway'\n",
        "              , 'quit', 'laugh', 'water', 'earth', 'evil', 'Dandi']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM4mRX1LUrM6",
        "colab_type": "text"
      },
      "source": [
        "2. Filter words not in vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xnL4ieVUudj",
        "colab_type": "code",
        "outputId": "a9097489-f6b7-422a-ade0-e8cbb0a5f8f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "filtered_words_list = filter_words_not_in_vocab(model, words_list)\n",
        "words_not_in_vocab = set(words_list) - set(filtered_words_list)\n",
        "print(\"Following {} words not in vocab:\".format(len(words_not_in_vocab)), words_not_in_vocab)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Following 1 words not in vocab: {'Putli_Bai'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HBtHl9gU9CL",
        "colab_type": "text"
      },
      "source": [
        "3. Compute most similar words using our metric."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYK16P36U_5v",
        "colab_type": "code",
        "outputId": "d07b5180-a9dd-4b91-91e5-316898749d18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "closest_words = find_highest_frequency(model, filtered_words_list)\n",
        "closest_words = list(filter(filter_words_with_same_root(words_list), closest_words))\n",
        "pprint(closest_words)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-04 06:25:22,318 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['Gujarat',\n",
            " 'Porbander',\n",
            " 'Bhavnagar',\n",
            " 'Valsad',\n",
            " 'Junagadh',\n",
            " 'Navsari',\n",
            " 'Bharuch',\n",
            " 'Amreli',\n",
            " 'Bhatkal',\n",
            " 'Visakhapatnam',\n",
            " 'Hubli',\n",
            " 'Alappuzha',\n",
            " 'Kollam',\n",
            " 'Veraval',\n",
            " 'Jamnagar',\n",
            " 'Valsad_district',\n",
            " 'Nalgonda',\n",
            " 'Kolhapur',\n",
            " 'Bhadrak']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cygph8ifDZgY",
        "colab_type": "text"
      },
      "source": [
        "### Adding clues to words.\n",
        "Next we want to see can we enhance the results by adding clue information to the words.\n",
        "1. Define clue list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mas-bSvEDjyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clue_list = [\"Gandhi's birthplace\", \n",
        "             \"Gandhi's mother\", \n",
        "             \"Hey : Gandhi's last words\", \n",
        "             \"Gandhi was Magazine's Man of the Year in 1930\",\n",
        "             \"Young : A journal published by Gandhi\", \n",
        "             \"Gandhi and Kasturba were jailed at Khan palace\",\n",
        "             \"Khan Gaffar Khan was also known as Frontier Gandhi\",\n",
        "             \"Mahatma means Great\", \n",
        "             \"The spinning wheel made iconic by Gandhi\",\n",
        "             \"The villagers want bread not: quote by Gandhi\",\n",
        "             \"Gandhi's profession in South Africa\",\n",
        "             \"Sarojni became president of the Indian National Congress after Gandhi\",\n",
        "             \"Gandhi was thrown out of the train at Pietermaritzburg Station\",\n",
        "             \"Gandhi started the India Movement in 1942\",\n",
        "             \"First they ignore you, then they at you, then they fight you, then you win: quote by Gandhi\",\n",
        "             \"We may not be God, but we are of God, even as a little drop is of the ocean: quote by Gandhi\",\n",
        "             \"provides enough to satify every man's needs, but not every man's greed: quote by Gandhi\",\n",
        "             \"Good and are found together: quote by Gandhi\",\n",
        "             \"Gandhi led the Salt March to this beach\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NOzrExuEaX9",
        "colab_type": "text"
      },
      "source": [
        "2. Next, add a function which will extract nouns from the clue. We will use [nltk](https://en.wikipedia.org/wiki/Natural_Language_Toolkit), a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQDswg0TEjIo",
        "colab_type": "code",
        "outputId": "43ff57ff-2efc-4aaa-9e5a-bceb68e24ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "!python -m textblob.download_corpora"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojn_SUkCEgp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_nouns(txt):\n",
        "  return [w for (w, pos) in TextBlob(txt).pos_tags if pos[0] == 'N']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n94E3zymGUr_",
        "colab_type": "code",
        "outputId": "6786ff9b-02da-4583-c1a9-88f218daecbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "from nltk import RegexpParser\n",
        "from nltk import Tree\n",
        "import pandas as pd\n",
        "\n",
        "# Defining a grammar & Parser\n",
        "NP = \"NP: {(<V\\w+>|<NN\\w?>)+.*<NN\\w?>}\"\n",
        "chunker = RegexpParser(NP)\n",
        "\n",
        "def get_continuous_chunks(text, chunk_func=ne_chunk):\n",
        "    chunked = chunk_func(pos_tag(word_tokenize(text)))\n",
        "    continuous_chunk = []\n",
        "    current_chunk = []\n",
        "\n",
        "    for subtree in chunked:\n",
        "        if type(subtree) == Tree:\n",
        "            current_chunk.append(\" \".join([token for token, pos in subtree.leaves()]))\n",
        "        elif current_chunk:\n",
        "            named_entity = \" \".join(current_chunk)\n",
        "            if named_entity not in continuous_chunk:\n",
        "                continuous_chunk.append(named_entity)\n",
        "                current_chunk = []\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    return continuous_chunk"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JaEoas3Ey8D",
        "colab_type": "text"
      },
      "source": [
        "3. Extract nouns for each clue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKV5l2X4E2kN",
        "colab_type": "code",
        "outputId": "497db935-c610-44f7-89e4-0f3c295e47e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "clue_nouns = list(map(extract_nouns, clue_list))\n",
        "pprint(clue_nouns)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Gandhi', 'birthplace'],\n",
            " ['Gandhi', 'mother'],\n",
            " ['Hey', 'Gandhi', 'words'],\n",
            " ['Gandhi', 'Magazine', 'Man', 'Year'],\n",
            " ['Young', 'journal', 'Gandhi'],\n",
            " ['Gandhi', 'Kasturba', 'Khan', 'palace'],\n",
            " ['Khan', 'Gaffar', 'Khan', 'Frontier', 'Gandhi'],\n",
            " ['Mahatma', 'Great'],\n",
            " ['spinning', 'wheel', 'Gandhi'],\n",
            " ['villagers', 'quote', 'Gandhi'],\n",
            " ['Gandhi', 'profession', 'South', 'Africa'],\n",
            " ['Sarojni', 'president', 'National', 'Congress', 'Gandhi'],\n",
            " ['Gandhi', 'train', 'Pietermaritzburg', 'Station'],\n",
            " ['Gandhi', 'India', 'Movement'],\n",
            " ['quote', 'Gandhi'],\n",
            " ['God', 'God', 'drop', 'ocean', 'quote', 'Gandhi'],\n",
            " ['man', 'needs', 'man', 'greed', 'quote', 'Gandhi'],\n",
            " ['quote', 'Gandhi'],\n",
            " ['Gandhi', 'Salt', 'March', 'beach']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1O27Gd-MZ4f",
        "colab_type": "text"
      },
      "source": [
        "Let us try to extract the noun phrases too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_Bil9GvMdaT",
        "colab_type": "code",
        "outputId": "53bbb201-f8ee-4a43-f543-3dcf8bb82806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "clue_noun_phrases = list(map(get_continuous_chunks, clue_list))\n",
        "pprint(clue_noun_phrases)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Gandhi'],\n",
            " ['Gandhi'],\n",
            " ['Gandhi'],\n",
            " ['Gandhi', 'Magazine'],\n",
            " ['Young'],\n",
            " ['Gandhi', 'Kasturba', 'Khan'],\n",
            " ['Khan Gaffar Khan'],\n",
            " ['Mahatma'],\n",
            " [],\n",
            " [],\n",
            " ['Gandhi'],\n",
            " ['Sarojni', 'Indian National Congress'],\n",
            " ['Gandhi'],\n",
            " ['Gandhi', 'India'],\n",
            " [],\n",
            " ['God'],\n",
            " [],\n",
            " ['Good'],\n",
            " ['Gandhi', 'Salt']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON8RX6n-Gu59",
        "colab_type": "text"
      },
      "source": [
        "Since the noun phrases are not that good, we stick to simply using the nouns. Next, we can try adding these words also as input to the model and see the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Y17l5gG0T4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flattened_clue_list = [item for sublist in clue_nouns for item in sublist]\n",
        "added_words_list = words_list + flattened_clue_list\n",
        "#pprint(added_words_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymwYDdj9HtZB",
        "colab_type": "text"
      },
      "source": [
        "Again, filter out the words not in vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPstRuzQHyQt",
        "colab_type": "code",
        "outputId": "3355e044-2ae1-43a8-ea57-58d80490aaa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "filtered_words_list = filter_words_not_in_vocab(model, added_words_list)\n",
        "words_not_in_vocab = set(added_words_list) - set(filtered_words_list)\n",
        "print(\"Following {} words not in vocab:\".format(len(words_not_in_vocab)), words_not_in_vocab)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Following 1 words not in vocab: {'Putli_Bai'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bnod_9jCIKO6"
      },
      "source": [
        "Compute most similar words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0HM7mw-3IOzJ",
        "outputId": "c6ea4529-eae1-4d7b-fd89-29d1e06a2c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "closest_words = find_highest_frequency(model, filtered_words_list, nwords=40)\n",
        "closest_words = list(filter(filter_words_with_same_root(added_words_list), closest_words))\n",
        "pprint(closest_words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['salt_satyagraha',\n",
            " 'Karunanidhi',\n",
            " 'Gadkari',\n",
            " 'Joshi',\n",
            " 'Vinoba',\n",
            " 'Bapu',\n",
            " 'Ambedkar',\n",
            " 'Pandit_Nehru',\n",
            " 'Swami_Vivekananda',\n",
            " 'Tagore',\n",
            " 'Hind_Swaraj',\n",
            " 'Shri_Guruji',\n",
            " 'Bhagat_Singh',\n",
            " 'Advani',\n",
            " 'Mayawati',\n",
            " 'Modi',\n",
            " 'Rahul',\n",
            " 'Basu',\n",
            " 'Mamata',\n",
            " 'Subhash_Chandra_Bose',\n",
            " 'Ghandi',\n",
            " 'Vinoba_Bhave']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbC9CIsPIoOi",
        "colab_type": "text"
      },
      "source": [
        "We can also try merging the clues and the words list, so that we get top word which is most similar, and feed them to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhu7yn8lIzG0",
        "colab_type": "code",
        "outputId": "17b8bd3c-b78b-457f-f830-c0e476846d56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "clues_words_combined = []\n",
        "for x in range(len(words_list)):\n",
        "  clues_words_combined.append(filter_words_not_in_vocab(model,[words_list[x]] + clue_nouns[x]))\n",
        "# replace each word list by most similar word\n",
        "closest_words = []\n",
        "for x in clues_words_combined:\n",
        "  words = model.most_similar(positive=x, topn=1)\n",
        "  words = [x[0] for x in words]\n",
        "  closest_words += words\n",
        "pprint(closest_words)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['Kirti_Mandir',\n",
            " 'grandmother',\n",
            " 'Jai_Sri',\n",
            " 'Life_Expectancy_Hits',\n",
            " 'Sunil_Khilnani',\n",
            " 'Bahadur_Shah',\n",
            " 'Hussain',\n",
            " 'Mahatma_Gandhi',\n",
            " 'charkha',\n",
            " 'Gandhiji',\n",
            " 'Francois_Joubert',\n",
            " 'Orissa_Pradesh',\n",
            " 'railway_station',\n",
            " 'Gandhiji',\n",
            " 'quip',\n",
            " 'Mans_REBELLION',\n",
            " 'Manners_maketh',\n",
            " 'Gandhiji',\n",
            " 'Dandi_march']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDnWDIP8TqLF",
        "colab_type": "text"
      },
      "source": [
        "We can even try getting closest words from these words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHEzyraeT1EX",
        "colab_type": "code",
        "outputId": "4c5dc7fd-9368-4082-c8d6-809502a28f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "result_words = find_highest_frequency(model, closest_words, nwords=40)\n",
        "result_words = list(filter(filter_words_with_same_root(added_words_list), result_words))\n",
        "# remove potential duplicates\n",
        "final_words = []\n",
        "for word in result_words:\n",
        "  is_similar = False\n",
        "  for x in final_words:\n",
        "    if stemmer.stem(x) == stemmer.stem(word) or x in word or word in x:\n",
        "      is_similar = True\n",
        "      break\n",
        "  if not is_similar:\n",
        "    final_words.append(word)\n",
        "pprint(final_words)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['Sabarmati_Ashram',\n",
            " 'Shivaji_Maharaj',\n",
            " 'satyagraha',\n",
            " 'Acharya_Vinoba_Bhave',\n",
            " 'Swami_Vivekananda',\n",
            " 'Bapu',\n",
            " 'Ambedkar',\n",
            " 'Hind_Swaraj',\n",
            " 'Pandit_Nehru',\n",
            " 'Sree_Narayana_Guru',\n",
            " 'Tagore',\n",
            " 'Bhagat_Singh',\n",
            " 'Shri_Guruji',\n",
            " 'Basavanna',\n",
            " 'Pandit_Jawaharlal_Nehru',\n",
            " 'Golwalkar']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vjp_QBZD2A3H",
        "colab_type": "code",
        "outputId": "af07334b-009b-4786-ef9a-c46334609126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model.most_similar(positive=[\"husband\", \"Kasturba\"], negative=[\"Gandhi\"], topn=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('wife', 0.631434440612793)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBlSdj5s9IFH",
        "colab_type": "text"
      },
      "source": [
        "Let us try to establish relationships between words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH7SQUDz9MFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def unit_vector(vector):\n",
        "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
        "    return vector / np.linalg.norm(vector)\n",
        "\n",
        "def angle_between(v1, v2):\n",
        "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
        "\n",
        "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
        "            1.5707963267948966\n",
        "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
        "            0.0\n",
        "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
        "            3.141592653589793\n",
        "    \"\"\"\n",
        "    v1_u = unit_vector(v1)\n",
        "    v2_u = unit_vector(v2)\n",
        "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "   v1_u = unit_vector(v1)\n",
        "   v2_u = unit_vector(v2)\n",
        "   return np.dot(v1_u, v2_u)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqaxnHkbR5h1",
        "colab_type": "code",
        "outputId": "2789b972-b80a-4bea-892f-3755714f9408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "a = \"China\"\n",
        "b = \"Beijing\"\n",
        "a_vector_list = model.most_similar(positive=[a], topn=10)\n",
        "b_vector_list = model.most_similar(positive=[b], topn=10)\n",
        "for v in a_vector_list:\n",
        "  for w in b_vector_list:\n",
        "    similar = model.most_similar(positive=[v[0], b], negative=[a], topn=1)\n",
        "    similar = [x[0] for x in similar]\n",
        "    if(w[0] in similar):\n",
        "      print(v[0], w[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Beijing Bejing\n",
            "Taiwan Taipei\n",
            "Chinas Bejing\n",
            "Shanghai Guangzhou\n",
            "Guangdong Guangzhou\n",
            "Hong_Kong Shanghai\n",
            "Shenzhen Guangzhou\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}